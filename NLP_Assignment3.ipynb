{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "89603959",
      "metadata": {
        "id": "89603959"
      },
      "source": [
        "# Natural Language Processing Assignment 3: The Notebook\n",
        "\n",
        "This is the notebook for the third and final hand-in assignment for Natural Language Processing. The notebook counts for 100% of the total assignment, the total assignment counts towards 20% of the final grade.\n",
        "\n",
        "In this notebook, you will be using the Huggingface Transformers library to work with pretrained transformer-based language models. Our running task will be: Natural Language Inference.\n",
        "\n",
        "The assignment broadly consists of three parts:\n",
        "\n",
        "1. Data preparation: where you will learn about the task, and prepare the data to be consumed by your PyTorch model.\n",
        "2. Model finetuning: where you finetune a `transformers` model on the task.\n",
        "3. Multilingual comparison: where you will compare the results on the English dataset to results on its Dutch incarnation.\n",
        "4. In-context learning: where you see how well a non-finetuned generative model like GPT-2 works on the same task.\n",
        "\n",
        "\n",
        "### Note\n",
        "When finetuning huggingface models, the models are saved to your computer. These files can be big (500MB-1GB), so do not hand them in! Instead, make sure that all cell outputs after running the code are visible (so: not cleared) when you hand in the assignment, this way we can see that you've done the training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "181e0149",
      "metadata": {
        "id": "181e0149"
      },
      "source": [
        "## Part 1 (14 points): Data preparation\n",
        "\n",
        "In this part you will familiarize yourself with the task at hand: Natural Language Inference. Recall from the course lectures that Natural Language Inference is a three-way sequence classification task over two sentences. Given a premise and a hypothesis, the task is to decide whether the premise Entails, Contradicts, or is Neutral with respect to the hypothesis. We will work with the SICK (Sentences Involving Compositional Knowledge) dataset of (Marelli et al. 2014) and its Dutch incarnation (Wijnholds & Moortgat, 2021).\n",
        "\n",
        "But first, we need to ensure that we have all the right packages installed, and then make some initial package imports, as usual. We assume that by now you have `torch` already installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fa29e2b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa29e2b1",
        "outputId": "f5ffcd9d-e77a-4e39-ad68-0f4063c8baa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.5.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (3.0.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# HuggingFace Transformers library ([torch] is used to get the correct version of accelerate)\n",
        "!pip install transformers[torch]\n",
        "# HuggingFace Datasets library\n",
        "!pip install datasets\n",
        "# HuggingFace Evaluate library\n",
        "!pip install evaluate\n",
        "# Scikit Learn, for evaluation metrics and confusion matrix\n",
        "!pip install scikit-learn\n",
        "# Seaborn, for nice plots\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6387c862",
      "metadata": {
        "id": "6387c862"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "225e290b",
      "metadata": {
        "id": "225e290b"
      },
      "source": [
        "### The SICK Dataset\n",
        "\n",
        "The SICK dataset was introduced in 2014 as one of the first dataset to measure relatedness between full sentences, but additionally also is labelled with Natural Language Inference labels. The good news for us is that the Dutch version of SICK, the SICK-NL dataset, is actually on the HuggingFace Hub: ['maximedb/sick_nl'](https://huggingface.co/datasets/maximedb/sick_nl). You can go ahead and check out some samples through the link, or check out the code below; loading the data is now incredibly simple:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "3bfd967c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3bfd967c",
        "outputId": "c956b36f-6743-4ca8-f25b-fc4b47f6bb9e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>datasets.arrow_dataset.Dataset</b><br/>def __init__(arrow_table: Table, info: Optional[DatasetInfo]=None, split: Optional[NamedSplit]=None, indices_table: Optional[Table]=None, fingerprint: Optional[str]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py</a>A Dataset backed by an Arrow table.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 631);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 1,\n",
              " 'sentence_A': 'Een groepje kinderen speelt in een tuin en een oude man staat op de achtergrond',\n",
              " 'sentence_B': 'Een groep jongens in een tuin is aan het spelen en een man staat op de achtergrond',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 4.5,\n",
              " 'entailment_AB': 'A_neutral_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'A group of kids is playing in a yard and an old man is standing in the background',\n",
              " 'sentence_B_original': 'A group of boys in a yard is playing and a man is standing in the background',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 2,\n",
              " 'sentence_A': 'Een groep kinderen speelt in het huis en er staat geen man op de achtergrond',\n",
              " 'sentence_B': 'Een groepje kinderen speelt in een tuin en een oude man staat op de achtergrond',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 3.2,\n",
              " 'entailment_AB': 'A_contradicts_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'A group of children is playing in the house and there is no man standing in the background',\n",
              " 'sentence_B_original': 'A group of kids is playing in a yard and an old man is standing in the background',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 3,\n",
              " 'sentence_A': 'De jonge jongens spelen buiten en de man lacht in de buurt',\n",
              " 'sentence_B': 'De kinderen spelen buiten in de buurt van een man met een glimlach',\n",
              " 'entailment_label': 'ENTAILMENT',\n",
              " 'relatedness_score': 4.7,\n",
              " 'entailment_AB': 'A_entails_B',\n",
              " 'entailment_BA': 'B_entails_A',\n",
              " 'sentence_A_original': 'The young boys are playing outdoors and the man is smiling nearby',\n",
              " 'sentence_B_original': 'The kids are playing outdoors near a man with a smile',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 2,\n",
              " 'label_seq2seq': '3'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 5,\n",
              " 'sentence_A': 'De kinderen spelen buiten in de buurt van een man met een glimlach',\n",
              " 'sentence_B': 'Een groepje kinderen speelt in een tuin en een oude man staat op de achtergrond',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 3.4,\n",
              " 'entailment_AB': 'A_neutral_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'The kids are playing outdoors near a man with a smile',\n",
              " 'sentence_B_original': 'A group of kids is playing in a yard and an old man is standing in the background',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 9,\n",
              " 'sentence_A': 'De jonge jongens spelen buiten en de man lacht in de buurt',\n",
              " 'sentence_B': 'Een groepje kinderen speelt in een tuin en een oude man staat op de achtergrond',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 3.7,\n",
              " 'entailment_AB': 'A_neutral_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'The young boys are playing outdoors and the man is smiling nearby',\n",
              " 'sentence_B_original': 'A group of kids is playing in a yard and an old man is standing in the background',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 12,\n",
              " 'sentence_A': 'Twee honden zijn aan het vechten',\n",
              " 'sentence_B': 'Twee honden zijn aan het worstelen en knuffelen',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 4.0,\n",
              " 'entailment_AB': 'A_neutral_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'Two dogs are fighting',\n",
              " 'sentence_B_original': 'Two dogs are wrestling and hugging',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 14,\n",
              " 'sentence_A': 'Een bruine hond valt een ander dier aan voor de man in een broek',\n",
              " 'sentence_B': 'Twee honden zijn aan het vechten',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 3.5,\n",
              " 'entailment_AB': 'A_neutral_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'A brown dog is attacking another animal in front of the man in pants',\n",
              " 'sentence_B_original': 'Two dogs are fighting',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 18,\n",
              " 'sentence_A': 'Een bruine hond valt een ander dier aan voor de man in een broek',\n",
              " 'sentence_B': 'Twee honden zijn aan het worstelen en knuffelen',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 3.2,\n",
              " 'entailment_AB': 'A_neutral_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'A brown dog is attacking another animal in front of the man in pants',\n",
              " 'sentence_B_original': 'Two dogs are wrestling and hugging',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 25,\n",
              " 'sentence_A': 'Niemand rijdt op de fiets op één wiel',\n",
              " 'sentence_B': 'Iemand in een zwart jasje doet trucjes op een motor',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 2.8,\n",
              " 'entailment_AB': 'A_contradicts_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'Nobody is riding the bicycle on one wheel',\n",
              " 'sentence_B_original': 'A person in a black jacket is doing tricks on a motorbike',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 26,\n",
              " 'sentence_A': 'Een persoon rijdt op de fiets op één wiel',\n",
              " 'sentence_B': 'Een man in een zwart jasje doet trucjes op een motor',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 3.7,\n",
              " 'entailment_AB': 'A_neutral_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'A person is riding the bicycle on one wheel',\n",
              " 'sentence_B_original': 'A man in a black jacket is doing tricks on a motorbike',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 28,\n",
              " 'sentence_A': 'Een persoon op een zwarte motor doet trucjes met een jasje',\n",
              " 'sentence_B': 'Een persoon rijdt op de fiets op één wiel',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 3.4,\n",
              " 'entailment_AB': 'A_neutral_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'A person on a black motorbike is doing tricks with a jacket',\n",
              " 'sentence_B_original': 'A person is riding the bicycle on one wheel',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 30,\n",
              " 'sentence_A': 'Een man met een trui is de bal aan het dunken bij een basketbalwedstrijd',\n",
              " 'sentence_B': 'De bal wordt gedunkt door een man met een trui bij een basketbalwedstrijd',\n",
              " 'entailment_label': 'ENTAILMENT',\n",
              " 'relatedness_score': 4.9,\n",
              " 'entailment_AB': 'A_entails_B',\n",
              " 'entailment_BA': 'B_entails_A',\n",
              " 'sentence_A_original': 'A man with a jersey is dunking the ball at a basketball game',\n",
              " 'sentence_B_original': 'The ball is being dunked by a man with a jersey at a basketball game',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 2,\n",
              " 'label_seq2seq': '3'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 35,\n",
              " 'sentence_A': 'Een man met een trui is de bal aan het dunken bij een basketbalwedstrijd',\n",
              " 'sentence_B': 'Een man die speelt, dunkt de basketbal in het net en het publiek is op de achtergrond',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 3.6,\n",
              " 'entailment_AB': 'A_neutral_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'A man with a jersey is dunking the ball at a basketball game',\n",
              " 'sentence_B_original': 'A man who is playing dunks the basketball into the net and a crowd is in background',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 40,\n",
              " 'sentence_A': 'De speler is de basketbal in het net aan het dunken en er is een menigte op de achtergrond',\n",
              " 'sentence_B': 'Een man met een trui is de bal aan het dunken bij een basketbalwedstrijd',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 3.8,\n",
              " 'entailment_AB': 'A_neutral_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'The player is dunking the basketball into the net and a crowd is in background',\n",
              " 'sentence_B_original': 'A man with a jersey is dunking the ball at a basketball game',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 42,\n",
              " 'sentence_A': 'Twee mensen zijn aan het kickboksen en toeschouwers kijken niet',\n",
              " 'sentence_B': 'Twee mensen zijn aan het kickboksen en toeschouwers kijken toe',\n",
              " 'entailment_label': 'CONTRADICTION',\n",
              " 'relatedness_score': 3.4,\n",
              " 'entailment_AB': 'A_contradicts_B',\n",
              " 'entailment_BA': 'B_contradicts_A',\n",
              " 'sentence_A_original': 'Two people are kickboxing and spectators are not watching',\n",
              " 'sentence_B_original': 'Two people are kickboxing and spectators are watching',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 0,\n",
              " 'label_seq2seq': '1'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 44,\n",
              " 'sentence_A': 'Twee jonge vrouwen zijn aan het sparren in een kickboksgevecht',\n",
              " 'sentence_B': 'Twee vrouwen zijn aan het sparren in een kickbokswedstrijd',\n",
              " 'entailment_label': 'ENTAILMENT',\n",
              " 'relatedness_score': 4.9,\n",
              " 'entailment_AB': 'A_entails_B',\n",
              " 'entailment_BA': 'B_entails_A',\n",
              " 'sentence_A_original': 'Two young women are sparring in a kickboxing fight',\n",
              " 'sentence_B_original': 'Two women are sparring in a kickboxing match',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 2,\n",
              " 'label_seq2seq': '3'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 45,\n",
              " 'sentence_A': 'Twee jonge vrouwen zijn niet aan het sparren in een kickboksgevecht',\n",
              " 'sentence_B': 'Twee vrouwen zijn aan het sparren in een kickbokswedstrijd',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 3.9,\n",
              " 'entailment_AB': 'A_contradicts_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'Two young women are not sparring in a kickboxing fight',\n",
              " 'sentence_B_original': 'Two women are sparring in a kickboxing match',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 47,\n",
              " 'sentence_A': 'Twee mensen zijn aan het kickboksen en toeschouwers kijken toe',\n",
              " 'sentence_B': 'Twee jonge vrouwen zijn niet aan het sparren in een kickboksgevecht',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 3.415,\n",
              " 'entailment_AB': 'A_neutral_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'Two people are kickboxing and spectators are watching',\n",
              " 'sentence_B_original': 'Two young women are not sparring in a kickboxing fight',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 49,\n",
              " 'sentence_A': 'Twee vrouwen zijn aan het sparren in een kickbokswedstrijd',\n",
              " 'sentence_B': 'Twee mensen zijn aan het kickboksen en toeschouwers kijken niet',\n",
              " 'entailment_label': 'NEUTRAL',\n",
              " 'relatedness_score': 3.7,\n",
              " 'entailment_AB': 'A_neutral_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'Two women are sparring in a kickboxing match',\n",
              " 'sentence_B_original': 'Two people are kickboxing and spectators are not watching',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 1,\n",
              " 'label_seq2seq': '2'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'pair_ID': 55,\n",
              " 'sentence_A': 'Drie jongens springen in de bladeren',\n",
              " 'sentence_B': 'Drie kinderen springen in de bladeren',\n",
              " 'entailment_label': 'ENTAILMENT',\n",
              " 'relatedness_score': 4.4,\n",
              " 'entailment_AB': 'A_entails_B',\n",
              " 'entailment_BA': 'B_neutral_A',\n",
              " 'sentence_A_original': 'Three boys are jumping in the leaves',\n",
              " 'sentence_B_original': 'Three kids are jumping in the leaves',\n",
              " 'sentence_A_dataset': 'FLICKR',\n",
              " 'sentence_B_dataset': 'FLICKR',\n",
              " 'SemEval_set': 'TRAIN',\n",
              " 'label': 2,\n",
              " 'label_seq2seq': '3'}"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "raw_datasets = load_dataset('maximedb/sick_nl')\n",
        "display(type(raw_datasets['train']))\n",
        "for i in range(20):\n",
        "    display(raw_datasets['train'][i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd2203d1",
      "metadata": {
        "id": "fd2203d1"
      },
      "source": [
        "Isn't that sick? The example above shows the structure of the data, containing Dutch and English premise (`sentence_A`) and hypothesis (`sentence_B`) sentences. You may notice that `entailment_label` and `label`; the latter is just the integer version of the actual label.."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfbfffb3",
      "metadata": {
        "id": "bfbfffb3"
      },
      "source": [
        "### Part 1.1 (6 points):\n",
        "\n",
        "Check out some more examples of the train data, until you find out the correspondence between entailment labels and the integer versions of them. Prove it by finishing the implementation below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "da0f870a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da0f870a",
        "outputId": "4b6f0328-180b-4e5f-f793-43217e0358af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct mapping\n"
          ]
        }
      ],
      "source": [
        "label2id = {'CONTRADICTION': 0, 'NEUTRAL': 1, 'ENTAILMENT': 2}\n",
        "id2label = {0: 'CONTRADICTION', 1: 'NEUTRAL', 2:'ENTAILMENT'}\n",
        "check= False\n",
        "for i in raw_datasets['train']:\n",
        "    if label2id[i['entailment_label']] == i['label'] :\n",
        "        continue\n",
        "    else:\n",
        "      check = True\n",
        "      print(\"incorrect mapping or mistake\")\n",
        "\n",
        "if check == False:\n",
        "  print(\"correct mapping\")\n",
        "else:\n",
        "  print(\"incorrect mapping\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e96fac00",
      "metadata": {
        "id": "e96fac00"
      },
      "source": [
        "### Part 1.2 (8 points): Tokenization\n",
        "\n",
        "Now, as we've seen in the lectures and in the HuggingFace NLP course, we need to prepare the raw data in a form that `transformers` models will understand. Again, unlike the previous hand-in assignment, preparing the data is very simple. The below code loads a tokenizer for a BERT base model (uncased), and creates a tokenized version of the data, and prepares a data collator, which we will need to use to wrap everything up properly during training.\n",
        "\n",
        "The only missing part is the implementation of `tokenize_function` below. It takes in a data point (like the example printed above) and returns a tokenized model input, ready to pass to a BERT model. Finish its implementation, ensuring that it returns the correct tokenized input (refer to the slides if you need to recall how you tokenize a pair of sentences for BERT). You can run the test code underneath to verify your implementation."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KxrDcY92GKuf"
      },
      "id": "KxrDcY92GKuf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "dfc7c43f",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "dd48859c1cee4d62948a64e727b5bdc7",
            "9ec2668da0e64057821619ee918134e5",
            "7ab97892fd4143b2950564f58473a41e",
            "1d6e161df19644a080093a94044c9ebf",
            "f2b40b1c35254c7aa9e8eb76bbbbe6a8",
            "efaa6558f45240bfa32a1036aab12f32",
            "fb4e92f4833d4793a725582c6530154b",
            "bb7477e3178c4edf8dca60247a5d7bca",
            "fec797737cae473b9aabecec9baa1f5c",
            "1701006a515f4c20af1d26dabc984e38",
            "179be670e03c49a2a2be66fda56cf670"
          ]
        },
        "id": "dfc7c43f",
        "outputId": "a267ea5b-e3b5-40a4-e938-817300022851"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/495 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd48859c1cee4d62948a64e727b5bdc7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# Define the tokenization function\n",
        "def tokenize_function(tokenizer, example):\n",
        "    # Tokenize the input sentences\n",
        "    return tokenizer(\n",
        "        text=example['sentence_A'],\n",
        "        text_pair=example.get('sentence_B', None),\n",
        "        truncation=True, #handle max len\n",
        "        padding=False,  # handle later\n",
        "        max_length=512  # 512 max for bert apparently\n",
        "    )\n",
        "\n",
        "bert_name = 'bert-base-uncased'\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_name)\n",
        "tokenized_datasets = raw_datasets.map(lambda x: tokenize_function(bert_tokenizer, x), batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=bert_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_datasets['train'][0])\n",
        "print(tokenized_datasets['train'][0].get('input_ids'))  # Safely access input_ids\n",
        "print(raw_datasets['train'].column_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2J5CWZuCAKe",
        "outputId": "3e2660db-c30a-43ac-a8c3-66a33bda95a3"
      },
      "id": "N2J5CWZuCAKe",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pair_ID': 1, 'sentence_A': 'Een groepje kinderen speelt in een tuin en een oude man staat op de achtergrond', 'sentence_B': 'Een groep jongens in een tuin is aan het spelen en een man staat op de achtergrond', 'entailment_label': 'NEUTRAL', 'relatedness_score': 4.5, 'entailment_AB': 'A_neutral_B', 'entailment_BA': 'B_neutral_A', 'sentence_A_original': 'A group of kids is playing in a yard and an old man is standing in the background', 'sentence_B_original': 'A group of boys in a yard is playing and a man is standing in the background', 'sentence_A_dataset': 'FLICKR', 'sentence_B_dataset': 'FLICKR', 'SemEval_set': 'TRAIN', 'label': 1, 'label_seq2seq': '2', 'input_ids': [101, 25212, 2078, 24665, 8913, 2361, 6460, 2785, 7869, 2078, 11867, 4402, 7096, 1999, 25212, 2078, 10722, 2378, 4372, 25212, 2078, 15068, 3207, 2158, 2358, 11057, 2102, 6728, 2139, 9353, 11039, 2121, 16523, 15422, 102, 25212, 2078, 24665, 8913, 2361, 18528, 6132, 1999, 25212, 2078, 10722, 2378, 2003, 9779, 2078, 21770, 11867, 12260, 2078, 4372, 25212, 2078, 2158, 2358, 11057, 2102, 6728, 2139, 9353, 11039, 2121, 16523, 15422, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "[101, 25212, 2078, 24665, 8913, 2361, 6460, 2785, 7869, 2078, 11867, 4402, 7096, 1999, 25212, 2078, 10722, 2378, 4372, 25212, 2078, 15068, 3207, 2158, 2358, 11057, 2102, 6728, 2139, 9353, 11039, 2121, 16523, 15422, 102, 25212, 2078, 24665, 8913, 2361, 18528, 6132, 1999, 25212, 2078, 10722, 2378, 2003, 9779, 2078, 21770, 11867, 12260, 2078, 4372, 25212, 2078, 2158, 2358, 11057, 2102, 6728, 2139, 9353, 11039, 2121, 16523, 15422, 102]\n",
            "['pair_ID', 'sentence_A', 'sentence_B', 'entailment_label', 'relatedness_score', 'entailment_AB', 'entailment_BA', 'sentence_A_original', 'sentence_B_original', 'sentence_A_dataset', 'sentence_B_dataset', 'SemEval_set', 'label', 'label_seq2seq']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "5add1bcb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5add1bcb",
        "outputId": "011a6131-ad88-4463-9726-fcffb96de32c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs:\n",
            "[101, 25212, 2078, 24665, 8913, 2361, 6460, 2785, 7869, 2078, 11867, 4402, 7096, 1999, 25212, 2078, 10722, 2378, 4372, 25212, 2078, 15068, 3207, 2158, 2358, 11057, 2102, 6728, 2139, 9353, 11039, 2121, 16523, 15422, 102, 25212, 2078, 24665, 8913, 2361, 18528, 6132, 1999, 25212, 2078, 10722, 2378, 2003, 9779, 2078, 21770, 11867, 12260, 2078, 4372, 25212, 2078, 2158, 2358, 11057, 2102, 6728, 2139, 9353, 11039, 2121, 16523, 15422, 102]\n",
            "\n",
            "Token Type IDs:\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "\n",
            "Attention Mask:\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "print('Input IDs:')\n",
        "print(tokenized_datasets['train'][0]['input_ids'])\n",
        "print('\\nToken Type IDs:')\n",
        "print(tokenized_datasets['train'][0]['token_type_ids'])\n",
        "print('\\nAttention Mask:')\n",
        "print(tokenized_datasets['train'][0]['attention_mask'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68fc4c84",
      "metadata": {
        "id": "68fc4c84"
      },
      "source": [
        "## Part 2 (30 points): Finetuning BERT\n",
        "\n",
        "So far so good. Now it's time to finetune a BERT model! Don't worry, the dataset was chosen to be small enough for you to finetune on your own machine (and on CPU), if you have 8GB+ of working memory available. Okay let's get to it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aab48ac",
      "metadata": {
        "id": "3aab48ac"
      },
      "source": [
        "### Part 2.1 (6 Points)\n",
        "\n",
        "Given that we have the name of the BERT model we want to train, we need to load in a pretrained model. Finish the one-liner below to setup a model for three-way classification so you can finetune for Natural Language Inference:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "57ab5075",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ab5075",
        "outputId": "20029c31-e49c-42f5-9643-55a8b2fd40f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "bert_model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8a9de0d",
      "metadata": {
        "id": "c8a9de0d"
      },
      "source": [
        "Wow, a one-liner to define a whole model! Let's continue with the model training.."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20d2bb58",
      "metadata": {
        "id": "20d2bb58"
      },
      "source": [
        "### Part 2.2 (12 Points)\n",
        "\n",
        "Let's get to training. Again, HuggingFace provides us with a lot of built-in functionality. The code below sets everything up: `compute_metrics` implements the method for calculating accuracy during training, using the `evaluate` library. Then, we have to set up a `Trainer` with a number of `TrainingArguments`. Finish the implementation so that we will run for 3 epochs, with a training batch size low enough for your machine (on the test machine, an M1 MacBook Air 2020 with 16GB working memory, a batch size of 16 was used). Check what device the implementation is going to use (CPU, CUDA, MPS?)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "e2ea1b69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2ea1b69",
        "outputId": "6efec0f3-f646-4f43-8622-41d19a54d04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# def compute_metrics(eval_preds):\n",
        "#     accuracy = evaluate.load(\"accuracy\")\n",
        "#     logits, labels = eval_preds\n",
        "#     predictions = np.argmax(logits, axis=-1)\n",
        "#     return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# # If you're running on an M1/M2 MacBook, with MPS backend support,\n",
        "# # you can replace \"TrainingArguments\" by \"TrainingArgumentsWithMPSSupport\"\n",
        "# # If not, just ignore this Python class!\n",
        "# class TrainingArgumentsWithMPSSupport(TrainingArguments):\n",
        "\n",
        "#     @property\n",
        "#     def device(self) -> torch.device:\n",
        "#         if torch.cuda.is_available():\n",
        "#             return torch.device(\"cuda\")\n",
        "#         elif torch.backends.mps.is_available():\n",
        "#             return torch.device(\"mps\")\n",
        "#         else:\n",
        "#             return torch.device(\"cpu\")\n",
        "\n",
        "# training_args = TrainingArguments(\"my-trainer\",\n",
        "#                                   per_device_train_batch_size=NotImplemented,\n",
        "#                                   num_train_epochs=NotImplemented,\n",
        "#                                   logging_strategy=\"epoch\",\n",
        "#                                   evaluation_strategy=\"epoch\",\n",
        "#                                   save_strategy=\"epoch\",\n",
        "#                                   dataloader_num_workers=0,\n",
        "#                                   load_best_model_at_end=True,\n",
        "#                                   save_total_limit=2)\n",
        "\n",
        "# trainer = Trainer(\n",
        "#     bert_model,\n",
        "#     training_args,\n",
        "#     train_dataset=NotImplemented,\n",
        "#     eval_dataset=NotImplemented,\n",
        "#     data_collator=data_collator,\n",
        "#     tokenizer=bert_tokenizer,\n",
        "#     compute_metrics=compute_metrics\n",
        "# )\n",
        "# display(training_args.device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    accuracy = evaluate.load(\"accuracy\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Use the built-in TrainingArguments without modification\n",
        "training_args = TrainingArguments(\"my-trainer\",  # Directory for saving models and checkpoints\n",
        "    per_device_train_batch_size=16,  # Adjust batch size based on your machine\n",
        "    num_train_epochs=3,  # Train for 3 epochs\n",
        "    logging_strategy=\"epoch\",  # Log metrics at the end of each epoch\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate the model at the end of each epoch\n",
        "    save_strategy=\"epoch\",  # Save the model at the end of each epoch\n",
        "    dataloader_num_workers=0,  # Number of workers for data loading\n",
        "    load_best_model_at_end=True,  # Load the best model after training\n",
        "    save_total_limit=2,  # Keep the last 2 checkpoints\n",
        "    push_to_hub=False  # Do not push to Hugging Face Hub (optional)\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=bert_model,  # The model to train\n",
        "    args=training_args,  # Training arguments\n",
        "    train_dataset=tokenized_datasets[\"train\"],  # Training dataset\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],  # Evaluation dataset\n",
        "    data_collator=data_collator,  # Data collator for padding\n",
        "    compute_metrics=compute_metrics  # Compute metrics function\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1d78e92",
      "metadata": {
        "id": "e1d78e92"
      },
      "source": [
        "Now, press the button on the cell below, and make some tea while you wait for the finetuning to finish :-)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "9d58b3a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513,
          "referenced_widgets": [
            "291569370fa44b8fb3de40cb9551ddec",
            "d1c3d3839e2c425e867c3b9756bf279c",
            "8a503512860a41ff8c46026a9150c5e1",
            "9262ee2ce1554bb2924e1577357f2dd1",
            "c9ed43432070412d90295f4f446e3e37",
            "40d038d6682e45e2b9d18c98726bf9e3",
            "c00e1ca6c41243af909d410d762b4493",
            "c50a70740bcb4e839f012a1225ad0999",
            "27027ea5ad6f42929286169453b283ce",
            "83a65a95d97241d99b6706c0d6f19a7e",
            "7a8f0e43d55c4ef3ab527b4d8b0785a3"
          ]
        },
        "id": "9d58b3a2",
        "outputId": "30ca64e8-e935-40df-ce61-561ac2af7892"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241218_193957-v8ds2vy6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jessekroll2-leiden-university-medical-center/huggingface/runs/v8ds2vy6' target=\"_blank\">my-trainer</a></strong> to <a href='https://wandb.ai/jessekroll2-leiden-university-medical-center/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jessekroll2-leiden-university-medical-center/huggingface' target=\"_blank\">https://wandb.ai/jessekroll2-leiden-university-medical-center/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jessekroll2-leiden-university-medical-center/huggingface/runs/v8ds2vy6' target=\"_blank\">https://wandb.ai/jessekroll2-leiden-university-medical-center/huggingface/runs/v8ds2vy6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='299' max='834' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [299/834 1:02:46 < 1:53:04, 0.08 it/s, Epoch 1.07/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.691200</td>\n",
              "      <td>0.606709</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "291569370fa44b8fb3de40cb9551ddec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='834' max='834' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [834/834 2:57:58, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.691200</td>\n",
              "      <td>0.606709</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.432300</td>\n",
              "      <td>0.534876</td>\n",
              "      <td>0.779798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.297200</td>\n",
              "      <td>0.623345</td>\n",
              "      <td>0.773737</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=834, training_loss=0.47354761759440106, metrics={'train_runtime': 10808.152, 'train_samples_per_second': 1.232, 'train_steps_per_second': 0.077, 'total_flos': 452362882362804.0, 'train_loss': 0.47354761759440106, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d255e0f",
      "metadata": {
        "id": "5d255e0f"
      },
      "source": [
        "Finally, now use the `Trainer` (that already loaded the best performing checkpoint/epoch), to evaluate on the test set and display test accuracy. It should be above 80%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba7d37e",
      "metadata": {
        "id": "fba7d37e"
      },
      "outputs": [],
      "source": [
        "# 2.2b Solution:\n",
        "test_predictions = NotImplemented\n",
        "print('Test accuracy: ', test_predictions[2]['test_accuracy'])\n",
        "\n",
        "\n",
        "# 2.2b Solution:\n",
        "# Evaluate the model on the test set\n",
        "test_results = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
        "\n",
        "# Extract test accuracy from the evaluation results\n",
        "test_accuracy = test_results[\"eval_accuracy\"]\n",
        "\n",
        "# Print the test accuracy\n",
        "print('Test accuracy: ', test_accuracy)\n",
        "\n",
        "\n",
        "est_predictions = trainer.predict(test_dataset=tokenized_datasets[\"test\"])\n",
        "print('Test accuracy: ', test_predictions.metrics['test_accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "586adfea",
      "metadata": {
        "id": "586adfea"
      },
      "source": [
        "### Part 2.3 (12 Points)\n",
        "\n",
        "Wasn't that incredibly easy? However, we would like to have a bit more insight in the model's predictions now. For this, we are going to look into precision, recall, and F1 score for the different classes.\n",
        "First, complete the implementation below to retrieve, for the test set, the model's predicted labels and the correct labels. Then inspect the confusion matrix that comes out, and its pretty-printed heatmap version.\n",
        "Finally, the precision, recall and f1 score are also printed. Use those to explain the confusion matrix: are the model's predictions at the rows and the correct answers at the columns or the other way around?\n",
        "\n",
        "*If you're confused about what a confusion matrix is, check out [Scikit Learn's documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) or review the slides of Week 3 (the part on multiclass evaluation and micro/macro-averaging).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "394c7614",
      "metadata": {
        "id": "394c7614"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import seaborn as sns\n",
        "\n",
        "preds = NotImplemented\n",
        "trues = NotImplemented\n",
        "\n",
        "cf_matrix = confusion_matrix(trues, preds)\n",
        "display(cf_matrix)\n",
        "\n",
        "sns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "\n",
        "precision, recall, f1, support = precision_recall_fscore_support(trues, preds)\n",
        "display(precision)\n",
        "display(recall)\n",
        "display(f1)\n",
        "display(support)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07092925",
      "metadata": {
        "id": "07092925"
      },
      "source": [
        "## Part 3 (24 points): Multilingual comparison\n",
        "\n",
        "Hey, this dataset you're using... it contains English and Dutch! In fact, let's revisit an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "730e825d",
      "metadata": {
        "id": "730e825d"
      },
      "outputs": [],
      "source": [
        "display(raw_datasets['train'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ade2ee8e",
      "metadata": {
        "id": "ade2ee8e"
      },
      "source": [
        "In fact, the items in the dataset are all *aligned*. That is, each `sentence_A` is a Dutch translation of `sentence_A_original`, and each `sentence_B` is a translation of `sentence_B_original`. That means we could also finetune a Dutch BERT model on the same dataset! Your task for this part is to do exactly this, and then compare results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "812fda7d",
      "metadata": {
        "id": "812fda7d"
      },
      "source": [
        "### Part 3.1 (12 points)\n",
        "\n",
        "In this part, your task is quite simple: repeat the finetuning exactly as before, but now use:\n",
        "\n",
        "- (a) the Dutch sentences instead of the English ones\n",
        "- (b) a Dutch tokenizer and BERT model, as indicated below\n",
        "\n",
        "In the end, report the test set accuracy, and the other evaluation metrics (precision, recall, F1) exactly as above, again plotting the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6a24003",
      "metadata": {
        "id": "f6a24003"
      },
      "outputs": [],
      "source": [
        "nl_bert_name = 'GroNLP/bert-base-dutch-cased'\n",
        "nl_tokenizer = NotImplemented\n",
        "nl_model = NotImplemented\n",
        "NotImplemented"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd1620ee",
      "metadata": {
        "id": "cd1620ee"
      },
      "source": [
        "### Part 3.2 (12 points)\n",
        "Now we wish to quantify the difference between the Dutch and English model results. Execute the following:\n",
        "\n",
        "1. Gather those predictions and true labels for which the English and Dutch model disagree, quantifying the percentage of cases where they disagree.\n",
        "2. Then, calculate and display the English confusion matrix, and Dutch confusion matrix for these cases.\n",
        "3. Then report on your findings. For example, when the models disagree, does the English model have a stronger tendency to classify sentence pairs as Neutral?\n",
        "\n",
        "*Note: the heatmap plots are in separate cells to avoid Seaborn to plot them on top of each other :)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2db7c621",
      "metadata": {
        "id": "2db7c621"
      },
      "outputs": [],
      "source": [
        "dis_trues, dis_en_preds, dis_nl_preds = NotImplemented\n",
        "\n",
        "dis_en_cf_matrix = confusion_matrix(dis_trues, dis_en_preds)\n",
        "dis_nl_cf_matrix = confusion_matrix(dis_trues, dis_nl_preds)\n",
        "sns.heatmap(dis_en_cf_matrix, annot=True, cmap='Blues', fmt='g')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90ac7f7b",
      "metadata": {
        "id": "90ac7f7b"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(dis_nl_cf_matrix, annot=True, cmap='Blues', fmt='g')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4e7d06e-a41a-46fb-a8dc-236e9554c6e2",
      "metadata": {
        "id": "d4e7d06e-a41a-46fb-a8dc-236e9554c6e2"
      },
      "source": [
        "#### Explanation\n",
        "[Answer for 3. here]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7440dcd",
      "metadata": {
        "id": "e7440dcd"
      },
      "source": [
        "## Part 4 (32 points): In-context learning\n",
        "\n",
        "Okay, while it's great that we can reach high accuracy with low effort by using built-in functionality from HuggingFace, let's try and see if we can do without fine-tuning at all, and use *in-context learning* with a generative model on the exact same task.\n",
        "\n",
        "Recall that for in-context learning, we take a large pretrained generative model (like GPT-3) and pose it with a prompt that specifies our task format and then we hope it generates text for a new case that corresponds to the correct answer! In this way we can do classification as well.\n",
        "\n",
        "Now for the bad news: OpenAI never officially released their GPT-3+ models, so we will do with the last available version, GPT-2*. No worries though: since this model is so much smaller we can actually use it on our own machines ;-) in the end, you just need to change the model's name to try out a larger model as soon as you get your hands on a powerful enough computing device.\n",
        "\n",
        "Let's start with setting up the GPT-2 model in the right setting: text generation. We will make use of HuggingFace's built-in `pipeline` for this. Start by running the below code that sets up the generative model in text generation mode.\n",
        "\n",
        "**In fact, the version of GPT-2 we'll be using is not even the largest GPT-2 model around. But hey, you get the general idea right? Just swapping a model's name will allow us to perform the exact same task, just with a larger model.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bebdad53",
      "metadata": {
        "id": "bebdad53"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(0)\n",
        "model = \"gpt2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90fa1613",
      "metadata": {
        "id": "90fa1613"
      },
      "source": [
        "Now let's see how generation works with some starting prompt. Note that we're setting a seed to guarantee that the model will give the same output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7963f6e1",
      "metadata": {
        "id": "7963f6e1"
      },
      "outputs": [],
      "source": [
        "from transformers import set_seed\n",
        "set_seed(5287935)\n",
        "\n",
        "prompt = \"My incomplete sentence is\"\n",
        "sequences_full = pipe(prompt, max_new_tokens=15, return_full_text=True)\n",
        "sequences_generated = pipe(prompt, max_new_tokens=15, return_full_text=False)\n",
        "print(sequences_full[0]['generated_text'])\n",
        "print('\\n\\n')\n",
        "print(sequences_generated[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcd7786d",
      "metadata": {
        "id": "dcd7786d"
      },
      "source": [
        "Okay, let's try a serious NLI prompt. We will try a few-shot setting in which the model will have seen one example for each NLI label. The code below grabs one example for each label from the validation data, and places them in a prompt, which contains a test pair (Does \"This is difficult.\" entail \"This is easy.\"?). Then, we ask the model to generate the next few tokens to see if it gives some sensible prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf131347",
      "metadata": {
        "id": "bf131347"
      },
      "outputs": [],
      "source": [
        "co_example = raw_datasets['validation'][0]\n",
        "co_example_sentence_a = co_example['sentence_A_original']\n",
        "co_example_sentence_b = co_example['sentence_B_original']\n",
        "\n",
        "ne_example = raw_datasets['validation'][1]\n",
        "ne_example_sentence_a = ne_example['sentence_A_original']\n",
        "ne_example_sentence_b = ne_example['sentence_B_original']\n",
        "\n",
        "en_example = raw_datasets['validation'][7]\n",
        "en_example_sentence_a = en_example['sentence_A_original']\n",
        "en_example_sentence_b = en_example['sentence_B_original']\n",
        "\n",
        "prompt = f\"For Sentence A and Sentence B, classify as Entailment, Neutral, or Contradiction.\\n\\\n",
        "Sentence A: {co_example_sentence_a}\\nSentence B: {co_example_sentence_b}\\nNLI Label: Contradiction.\\n\\\n",
        "Sentence A: {ne_example_sentence_a}\\nSentence B: {ne_example_sentence_b}\\nNLI Label: Neutral.\\n\\\n",
        "Sentence A: {en_example_sentence_a}\\nSentence B: {en_example_sentence_b}\\nNLI Label: Entailment.\\n\\\n",
        "Sentence A: This is difficult.\\nSentence B: This is easy.\\n NLI Label:\"\n",
        "\n",
        "prompting_examples = pipe(prompt, max_new_tokens=3, return_full_text=False)\n",
        "print(prompting_examples[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "719ee3d5",
      "metadata": {
        "id": "719ee3d5"
      },
      "source": [
        "Pretty cool, right? Is the answer correct?\n",
        "\n",
        "If we want to systematically assess how well the model does on the full dataset, we will need a few ingredients, and these are the steps you will follow:\n",
        "\n",
        "1. A way to encode each sentence pair as a prompt.\n",
        "2. A loop to run the model on all of the prompts.\n",
        "3. Functionality to decode the model's output back to an NLI label."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40f0e889",
      "metadata": {
        "id": "40f0e889"
      },
      "source": [
        "### Part 4.1 (10 points)\n",
        "\n",
        "First off, implement the function `create_prompt` below, that returns an NLI prompt but with the two given sentences (A and B). Verify with the code underneath to see what happens.\n",
        "\n",
        "*Hint: you can re-use the prompt above in your solution.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f941efb",
      "metadata": {
        "id": "4f941efb"
      },
      "outputs": [],
      "source": [
        "def create_prompt(sentence_a, sentence_b):\n",
        "    NotImplemented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7226eef8",
      "metadata": {
        "id": "7226eef8"
      },
      "outputs": [],
      "source": [
        "ex = raw_datasets['test'][0]\n",
        "prompt = create_prompt(ex['sentence_A_original'], ex['sentence_B_original'])\n",
        "print(prompt)\n",
        "sequences = pipe(prompt, max_new_tokens=3, return_full_text=False)\n",
        "display(sequences)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3333132f",
      "metadata": {
        "id": "3333132f"
      },
      "source": [
        "### Part 4.2 (10 points)\n",
        "\n",
        "You may notice that the output is not exactly clean, and it could even be a completely different text than an NLI label! So you'll need to finish the function `decode_prompting_result` below, that will take the output of the generation and return an actual label. Note that the function should return the correct label if the output corresponds to an NLI label, and a fourth label in case the output is something different."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2549b3f6",
      "metadata": {
        "id": "2549b3f6"
      },
      "outputs": [],
      "source": [
        "def decode_prompting_result(result: str) -> int:\n",
        "    result_label = NotImplemented\n",
        "    if result_label in label2id:\n",
        "        return label2int[result_label]\n",
        "    else:\n",
        "        return NotImplemented"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a2e2986",
      "metadata": {
        "id": "0a2e2986"
      },
      "source": [
        "### Part 4.3 (5 points)\n",
        "\n",
        "Now to actually run the whole thing: for each item in the test data we want to create a prompt, feed it to the model, and transform the result into a label. We want to end up with a list of predictions, just like with the finetuned models before. The only difference will be that we have a fourth possible label. Run the below code as is (don't forget to make tea while you wait!), and run the code underneath to see a sample of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31fa7043",
      "metadata": {
        "id": "31fa7043"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "generation_preds = []\n",
        "for d in tqdm(raw_datasets['test']):\n",
        "    prompt = create_prompt(d['sentence_A_original'], d['sentence_B_original'])\n",
        "    results = pipe(prompt, max_new_tokens=3, return_full_text=False)\n",
        "    label = decode_prompting_result(results[0]['generated_text'])\n",
        "    generation_preds.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb41f5d6",
      "metadata": {
        "id": "bb41f5d6"
      },
      "outputs": [],
      "source": [
        "print(generation_preds[:50])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eedfe0b1",
      "metadata": {
        "id": "eedfe0b1"
      },
      "source": [
        "### Part 4.4 (7 points)\n",
        "\n",
        "As a last step, do what you do best and display the confusion matrix, precision, recall and F1 score for the prompting setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5a54a9a",
      "metadata": {
        "id": "c5a54a9a"
      },
      "outputs": [],
      "source": [
        "# Your 4.4 Solution:\n",
        "\n",
        "NotImplemented"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e6a2abe",
      "metadata": {
        "id": "9e6a2abe"
      },
      "source": [
        "### Bonus Exercise: Decoding strategies\n",
        "\n",
        "If you are unsatisfied with the result, you may be happy to know that you can apply the decoding strategies you saw in the lecture (such as beam search, top-k sampling, top-p nucleus sampling) also in the current context, by adding the same arguments to the `pipe` when you run it on a prompt. You will get bonus points for trying out at least two different generation strategies and seeing how this affects the result."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff8de56f",
      "metadata": {
        "id": "ff8de56f"
      },
      "source": [
        "### Alternative Bonus Exercise: Seed-averaging\n",
        "\n",
        "You may notice that text generation can be different on the same prompt each time that you run the model. You can score bonus points by running the model over the dataset three times and aggregating the results in a way you choose."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd48859c1cee4d62948a64e727b5bdc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ec2668da0e64057821619ee918134e5",
              "IPY_MODEL_7ab97892fd4143b2950564f58473a41e",
              "IPY_MODEL_1d6e161df19644a080093a94044c9ebf"
            ],
            "layout": "IPY_MODEL_f2b40b1c35254c7aa9e8eb76bbbbe6a8"
          }
        },
        "9ec2668da0e64057821619ee918134e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efaa6558f45240bfa32a1036aab12f32",
            "placeholder": "​",
            "style": "IPY_MODEL_fb4e92f4833d4793a725582c6530154b",
            "value": "Map: 100%"
          }
        },
        "7ab97892fd4143b2950564f58473a41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb7477e3178c4edf8dca60247a5d7bca",
            "max": 495,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fec797737cae473b9aabecec9baa1f5c",
            "value": 495
          }
        },
        "1d6e161df19644a080093a94044c9ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1701006a515f4c20af1d26dabc984e38",
            "placeholder": "​",
            "style": "IPY_MODEL_179be670e03c49a2a2be66fda56cf670",
            "value": " 495/495 [00:00&lt;00:00, 2528.35 examples/s]"
          }
        },
        "f2b40b1c35254c7aa9e8eb76bbbbe6a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efaa6558f45240bfa32a1036aab12f32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb4e92f4833d4793a725582c6530154b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb7477e3178c4edf8dca60247a5d7bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec797737cae473b9aabecec9baa1f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1701006a515f4c20af1d26dabc984e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "179be670e03c49a2a2be66fda56cf670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "291569370fa44b8fb3de40cb9551ddec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1c3d3839e2c425e867c3b9756bf279c",
              "IPY_MODEL_8a503512860a41ff8c46026a9150c5e1",
              "IPY_MODEL_9262ee2ce1554bb2924e1577357f2dd1"
            ],
            "layout": "IPY_MODEL_c9ed43432070412d90295f4f446e3e37"
          }
        },
        "d1c3d3839e2c425e867c3b9756bf279c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40d038d6682e45e2b9d18c98726bf9e3",
            "placeholder": "​",
            "style": "IPY_MODEL_c00e1ca6c41243af909d410d762b4493",
            "value": "Downloading builder script: 100%"
          }
        },
        "8a503512860a41ff8c46026a9150c5e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c50a70740bcb4e839f012a1225ad0999",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27027ea5ad6f42929286169453b283ce",
            "value": 4203
          }
        },
        "9262ee2ce1554bb2924e1577357f2dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83a65a95d97241d99b6706c0d6f19a7e",
            "placeholder": "​",
            "style": "IPY_MODEL_7a8f0e43d55c4ef3ab527b4d8b0785a3",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 261kB/s]"
          }
        },
        "c9ed43432070412d90295f4f446e3e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40d038d6682e45e2b9d18c98726bf9e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c00e1ca6c41243af909d410d762b4493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c50a70740bcb4e839f012a1225ad0999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27027ea5ad6f42929286169453b283ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83a65a95d97241d99b6706c0d6f19a7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8f0e43d55c4ef3ab527b4d8b0785a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}